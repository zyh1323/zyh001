# 大模型

## 理论基础

1. 分词和词嵌入：分词的目的是将一句话切分为多个token(BPE分词方法),词嵌入的目的是将词转化为词向量(One-hot编码，CBOW嵌入)。

2. RNN(序列模型)：当前时刻会利用到上一个时刻的信息进行推理。可以用于问答，翻译，词或者句子预测。

3. Transformer：
    (1)输入的处理：将词向量融入位置信息。
    (2)encoder：通过注意力机制进行交互计算，融入上下文信息。（注意力机制就是让当前词找到更加感兴趣的其他词，然后整合其他词的信息，Q查询，K键，V值）
    (3)decoder：通过交叉注意力机制整合输入信息，并且每次会把前面输出的文本当做输入进行新的预测，最后输出词的类别得分。

## 应用技术

1. 大模型的推理部署:
    (1)APi调用：openai接口
    (2)Transformers和vllm推理框架：消息列表，推理参数(top_p, top_k,temperature, do_sample, repetition_penalty,KV_cache)，多轮对话，流式推理。

2. 大模型的微调训练：
    (1)Lora微调：在原有的模型基础上进行二次微调，采用矩阵分解形式降低训练成本，只训练了一部分参数降低成本。
    (2)llamafactory工具：工具的部署，数据准备和模型准备，训练参数和lora参数。
    (3)lora模型的加载：peft库进行加载，lora学习程度。

3. 大模型的数据准备：
    (1)开源QA问答对或者甲方提供的QA问答对数据集。
    (2)文档中利用大模型自动抽取QA问答对，文档 -> pdf -> markdown(Mineru) -> 图片和文本(paddleocr) -> 文本
    (3)提示词工程：提示词模版(角色定义，任务，要求，示例),抽取QA格式转化。
 
